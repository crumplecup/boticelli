use botticelli_core::{Input, Message, Output, Role};
use botticelli_interface::BotticelliDriver;
use botticelli_models::AnthropicClient;

#[tokio::test]
#[cfg_attr(not(feature = "api"), ignore)]
async fn test_anthropic_generate() -> Result<(), Box<dyn std::error::Error>> {
    let api_key = std::env::var("ANTHROPIC_API_KEY")?;
    let client = AnthropicClient::new(api_key, "claude-3-5-sonnet-20241022".to_string());

    let message = Message::builder()
        .role(Role::User)
        .content(vec![Input::Text(
            "Say 'Hello' and nothing else.".to_string(),
        )])
        .build()?;

    let response = client.generate(vec![message]).await?;

    assert!(!response.outputs().is_empty());
    if let Some(Output::Text(text)) = response.outputs().first() {
        assert!(text.to_lowercase().contains("hello"));
    }

    Ok(())
}

#[tokio::test]
#[cfg_attr(not(feature = "api"), ignore)]
async fn test_anthropic_stream() -> Result<(), Box<dyn std::error::Error>> {
    use futures::StreamExt;

    let api_key = std::env::var("ANTHROPIC_API_KEY")?;
    let client = AnthropicClient::new(api_key, "claude-3-5-sonnet-20241022".to_string());

    let message = Message::builder()
        .role(Role::User)
        .content(vec![Input::Text("Count to 3.".to_string())])
        .build()?;

    let mut stream = client.stream(vec![message]).await?;

    let mut chunks = Vec::new();
    while let Some(chunk_result) = stream.next().await {
        let chunk = chunk_result?;
        chunks.push(chunk);
    }

    assert!(!chunks.is_empty(), "Should receive at least one chunk");

    Ok(())
}
